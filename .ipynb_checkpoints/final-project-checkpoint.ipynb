{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ac5ea4d",
   "metadata": {},
   "source": [
    "# Get the top 100 book title from Guardian\n",
    "Weichen Fang\n",
    "13218115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53f4ce27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The Pilgrim’s Progress', 'Robinson Crusoe', 'Gulliver’s Travels', 'Clarissa', 'Tom Jones', 'The Life and Opinions of Tristram Shandy, Gentleman', 'Emma', 'Frankenstein', 'Nightmare Abbey', 'Thomas Love Peacock', 'The Narrative of Arthur Gordon Pym of Nantucket', 'Sybil', 'Jane Eyre', 'Wuthering Heights', 'Vanity Fair', 'David Copperfield', 'The Scarlet Letter', 'Moby-Dick', 'Alice’s Adventures in Wonderland', 'The Moonstone', 'Little Women', 'Middlemarch', 'The Way We Live Now', 'The Adventures of Huckleberry Finn', 'Kidnapped', 'Three Men in a Boat', 'The Sign of Four', 'The Picture of Dorian Gray', 'New Grub Street', 'Jude the Obscure', 'The Red Badge of Courage', 'Dracula', 'Heart of Darkness', 'Sister Carrie', 'Kim', 'The Call of the Wild', 'The Golden Bowl', 'Hadrian the Seventh', 'The Wind in the Willows', 'The History of Mr Polly', 'Zuleika Dobson', 'The Good Soldier', 'The Thirty-Nine Steps', 'The Rainbow', 'Of Human Bondage', 'The Age of Innocence', 'Ulysses', 'Babbitt', 'A Passage to India', 'Gentlemen Prefer Blondes', 'Mrs Dalloway', 'The Great Gatsby', 'Lolly Willowes', 'The Sun Also Rises', 'The Maltese Falcon', 'As I Lay Dying', 'Brave New World', 'Cold Comfort Farm', 'Nineteen Nineteen', 'Tropic of Cancer', 'Scoop', 'Murphy', 'The Big Sleep', 'Party Going', 'At Swim-Two-Birds', 'The Grapes of Wrath', 'Joy in the Morning', 'All the King’s Men', 'Under the Volcano', 'The Heat of the Day', 'Nineteen Eighty-Four', 'The End of the Affair', 'The Catcher in the Rye', 'The Adventures of Augie March', 'Lord of the Flies', 'Lolita', 'On the Road', 'Voss', 'To Kill a Mockingbird', 'arrived this summer', 'The Prime of Miss Jean Brodie', 'Catch-22', 'The Golden Notebook', 'A Clockwork Orange', 'A Single Man', 'In Cold Blood', 'The Bell Jar', 'Portnoy’s Complaint', 'Mrs Palfrey at the Claremont', 'Rabbit Redux', 'Song of Solomon', 'A Bend in the River', 'Midnight’s Children', 'Housekeeping', 'Money: A Suicide Note', 'An Artist of the Floating World', 'The Beginning of Spring', 'Breathing Lessons', 'Amongst Women', 'Underworld', 'Disgrace', 'True History of the Kelly Gang']\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# get the top 100 book titles from The Guardian\n",
    "url = \"https://www.theguardian.com/books/2015/aug/17/the-100-best-novels-written-in-english-the-full-list\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "book_titles = soup.find_all(\"p\", class_=\"dcr-1a568om\")\n",
    "\n",
    "# Create an empty list\n",
    "book_list = []\n",
    "\n",
    "# Extract the book titles and add them to the list\n",
    "for title in book_titles:\n",
    "    book_link = title.find(\"a\")\n",
    "    if book_link is not None:\n",
    "        book_title = book_link.text.strip()\n",
    "        book_list.append(book_title)\n",
    "\n",
    "# Empty lists to store book details\n",
    "descriptions = []\n",
    "authors = []\n",
    "genres = []\n",
    "links = []\n",
    "print(book_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e901a91",
   "metadata": {},
   "source": [
    "# Scrap extra information for each top 100 book in Goodreads\n",
    "most elegant code I can come up with, but down side is this will running iteration to scrap evry think I want, from experience 4 times is enough to get the full dataframe, however this will take half an hour to run. \n",
    "thinking to use ways to optimize this, maybe selenium?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8e9f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred while scraping book 'The Pilgrim’s Progress': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'The Pilgrim’s Progress' (Iteration 1)...\n",
      "Error occurred while scraping book 'The Pilgrim’s Progress': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'The Pilgrim’s Progress' (Iteration 2)...\n",
      "Error occurred while scraping book 'Gulliver’s Travels': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'Gulliver’s Travels' (Iteration 1)...\n",
      "Error occurred while scraping book 'Gulliver’s Travels': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'Gulliver’s Travels' (Iteration 2)...\n",
      "Error occurred while scraping book 'Gulliver’s Travels': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'Gulliver’s Travels' (Iteration 3)...\n",
      "Error occurred while scraping book 'Gulliver’s Travels': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'Gulliver’s Travels' (Iteration 4)...\n",
      "Error occurred while scraping book 'Gulliver’s Travels': 'NoneType' object has no attribute 'find_all'\n",
      "Error occurred while scraping book 'Thomas Love Peacock': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'Thomas Love Peacock' (Iteration 1)...\n",
      "Error occurred while scraping book 'Thomas Love Peacock': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'Thomas Love Peacock' (Iteration 2)...\n",
      "Error occurred while scraping book 'Vanity Fair': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'Vanity Fair' (Iteration 1)...\n",
      "Error occurred while scraping book 'Vanity Fair': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'Vanity Fair' (Iteration 2)...\n",
      "Error occurred while scraping book 'Vanity Fair': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'Vanity Fair' (Iteration 3)...\n",
      "Error occurred while scraping book 'Vanity Fair': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'Vanity Fair' (Iteration 4)...\n",
      "Error occurred while scraping book 'Vanity Fair': 'NoneType' object has no attribute 'find_all'\n",
      "Error occurred while scraping book 'David Copperfield': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'David Copperfield' (Iteration 1)...\n",
      "Error occurred while scraping book 'The Adventures of Huckleberry Finn': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'The Adventures of Huckleberry Finn' (Iteration 1)...\n",
      "Error occurred while scraping book 'The Adventures of Huckleberry Finn': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'The Adventures of Huckleberry Finn' (Iteration 2)...\n",
      "Error occurred while scraping book 'The Adventures of Huckleberry Finn': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'The Adventures of Huckleberry Finn' (Iteration 3)...\n",
      "Error occurred while scraping book 'The Picture of Dorian Gray': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'The Picture of Dorian Gray' (Iteration 1)...\n",
      "Error occurred while scraping book 'The Picture of Dorian Gray': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'The Picture of Dorian Gray' (Iteration 2)...\n",
      "Error occurred while scraping book 'The Picture of Dorian Gray': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'The Picture of Dorian Gray' (Iteration 3)...\n",
      "Error occurred while scraping book 'New Grub Street': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'New Grub Street' (Iteration 1)...\n",
      "Error occurred while scraping book 'Jude the Obscure': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'Jude the Obscure' (Iteration 1)...\n",
      "Error occurred while scraping book 'Jude the Obscure': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'Jude the Obscure' (Iteration 2)...\n",
      "Error occurred while scraping book 'The Red Badge of Courage': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'The Red Badge of Courage' (Iteration 1)...\n",
      "Error occurred while scraping book 'The Red Badge of Courage': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'The Red Badge of Courage' (Iteration 2)...\n",
      "Error occurred while scraping book 'The Red Badge of Courage': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'The Red Badge of Courage' (Iteration 3)...\n",
      "Error occurred while scraping book 'The Red Badge of Courage': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'The Red Badge of Courage' (Iteration 4)...\n",
      "Error occurred while scraping book 'The Red Badge of Courage': 'NoneType' object has no attribute 'find_all'\n",
      "Error occurred while scraping book 'Heart of Darkness': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'Heart of Darkness' (Iteration 1)...\n",
      "Error occurred while scraping book 'Heart of Darkness': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'Heart of Darkness' (Iteration 2)...\n",
      "Error occurred while scraping book 'Sister Carrie': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'Sister Carrie' (Iteration 1)...\n",
      "Error occurred while scraping book 'Sister Carrie': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'Sister Carrie' (Iteration 2)...\n",
      "Error occurred while scraping book 'Sister Carrie': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'Sister Carrie' (Iteration 3)...\n",
      "Error occurred while scraping book 'Kim': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'Kim' (Iteration 1)...\n",
      "Error occurred while scraping book 'Kim': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'Kim' (Iteration 2)...\n",
      "Re-scraping book 'Kim' (Iteration 3)...\n",
      "Error occurred while scraping book 'Kim': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'Kim' (Iteration 4)...\n",
      "Error occurred while scraping book 'Kim': 'NoneType' object has no attribute 'find_all'\n",
      "Error occurred while scraping book 'The Golden Bowl': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'The Golden Bowl' (Iteration 1)...\n",
      "Error occurred while scraping book 'The Wind in the Willows': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'The Wind in the Willows' (Iteration 1)...\n",
      "Error occurred while scraping book 'Zuleika Dobson': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'Zuleika Dobson' (Iteration 1)...\n",
      "Error occurred while scraping book 'Zuleika Dobson': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'Zuleika Dobson' (Iteration 2)...\n",
      "Error occurred while scraping book 'Zuleika Dobson': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'Zuleika Dobson' (Iteration 3)...\n",
      "Error occurred while scraping book 'Zuleika Dobson': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'Zuleika Dobson' (Iteration 4)...\n",
      "Error occurred while scraping book 'Zuleika Dobson': 'NoneType' object has no attribute 'find_all'\n",
      "Error occurred while scraping book 'The Rainbow': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'The Rainbow' (Iteration 1)...\n",
      "Error occurred while scraping book 'The Rainbow': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'The Rainbow' (Iteration 2)...\n",
      "Error occurred while scraping book 'The Rainbow': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'The Rainbow' (Iteration 3)...\n",
      "Error occurred while scraping book 'The Rainbow': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'The Rainbow' (Iteration 4)...\n",
      "Error occurred while scraping book 'The Rainbow': 'NoneType' object has no attribute 'find_all'\n",
      "Error occurred while scraping book 'The Age of Innocence': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'The Age of Innocence' (Iteration 1)...\n",
      "Error occurred while scraping book 'Gentlemen Prefer Blondes': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'Gentlemen Prefer Blondes' (Iteration 1)...\n",
      "Error occurred while scraping book 'The Great Gatsby': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'The Great Gatsby' (Iteration 1)...\n",
      "Error occurred while scraping book 'The Great Gatsby': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'The Great Gatsby' (Iteration 2)...\n",
      "Error occurred while scraping book 'Lolly Willowes': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'Lolly Willowes' (Iteration 1)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred while scraping book 'Lolly Willowes': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'Lolly Willowes' (Iteration 2)...\n",
      "Error occurred while scraping book 'Lolly Willowes': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'Lolly Willowes' (Iteration 3)...\n",
      "Error occurred while scraping book 'As I Lay Dying': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'As I Lay Dying' (Iteration 1)...\n",
      "Error occurred while scraping book 'Brave New World': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'Brave New World' (Iteration 1)...\n",
      "Error occurred while scraping book 'Brave New World': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'Brave New World' (Iteration 2)...\n",
      "Error occurred while scraping book 'Tropic of Cancer': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'Tropic of Cancer' (Iteration 1)...\n",
      "Error occurred while scraping book 'Tropic of Cancer': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'Tropic of Cancer' (Iteration 2)...\n",
      "Error occurred while scraping book 'Tropic of Cancer': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'Tropic of Cancer' (Iteration 3)...\n",
      "Error occurred while scraping book 'Tropic of Cancer': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'Tropic of Cancer' (Iteration 4)...\n",
      "Error occurred while scraping book 'Tropic of Cancer': 'NoneType' object has no attribute 'find_all'\n",
      "Error occurred while scraping book 'Scoop': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'Scoop' (Iteration 1)...\n",
      "Error occurred while scraping book 'Murphy': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'Murphy' (Iteration 1)...\n",
      "Error occurred while scraping book 'Murphy': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'Murphy' (Iteration 2)...\n",
      "Error occurred while scraping book 'The Big Sleep': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'The Big Sleep' (Iteration 1)...\n",
      "Error occurred while scraping book 'The Big Sleep': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'The Big Sleep' (Iteration 2)...\n",
      "Error occurred while scraping book 'The Big Sleep': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'The Big Sleep' (Iteration 3)...\n",
      "Error occurred while scraping book 'Party Going': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'Party Going' (Iteration 1)...\n",
      "Error occurred while scraping book 'At Swim-Two-Birds': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'At Swim-Two-Birds' (Iteration 1)...\n",
      "Error occurred while scraping book 'At Swim-Two-Birds': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'At Swim-Two-Birds' (Iteration 2)...\n",
      "Error occurred while scraping book 'At Swim-Two-Birds': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'At Swim-Two-Birds' (Iteration 3)...\n",
      "Error occurred while scraping book 'The Grapes of Wrath': 'NoneType' object has no attribute 'find_all'\n",
      "Re-scraping book 'The Grapes of Wrath' (Iteration 1)...\n"
     ]
    }
   ],
   "source": [
    "#final version with iteration\n",
    "from bs4 import BeautifulSoup\n",
    "# Function to scrape book details\n",
    "def scrape_book_details(book):\n",
    "    try:\n",
    "        # Creating search query for Goodreads\n",
    "        search_query = book.replace(\" \", \"+\")\n",
    "        url = f\"https://www.goodreads.com/search?q={search_query}\"\n",
    "\n",
    "        # Making HTTP GET request\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        # Finding the first search result (most relevant) from Goodreads\n",
    "        search_result = soup.find(\"a\", class_=\"bookTitle\")\n",
    "\n",
    "        if search_result:\n",
    "            # Extracting book details if search result is found\n",
    "            book_url = \"https://www.goodreads.com\" + search_result[\"href\"]\n",
    "            book_response = requests.get(book_url)\n",
    "            book_soup = BeautifulSoup(book_response.content, \"html.parser\")\n",
    "\n",
    "            # Extracting book description\n",
    "            description_element = book_soup.find(\"div\", {\"data-testid\": \"description\"})\n",
    "            description = description_element.find(\"span\", class_=\"Formatted\").text.strip() if description_element else \"N/A\"\n",
    "\n",
    "            # Extracting author\n",
    "            author_element = book_soup.find(\"span\", class_=\"ContributorLink__name\")\n",
    "            author = author_element.text.strip() if author_element else \"N/A\"\n",
    "\n",
    "            # Extracting genres\n",
    "            genres_element = book_soup.find(\"div\", {\"data-testid\": \"genresList\"})\n",
    "            genre_links = genres_element.find_all(\"a\", class_=\"Button Button--tag-inline Button--small\")\n",
    "            genre_list = [genre.text.strip() for genre in genre_links] if genre_links else [\"N/A\"]\n",
    "\n",
    "            return description, author, book_url, genre_list\n",
    "        else:\n",
    "            return \"N/A\", \"N/A\", \"N/A\", [\"N/A\"]\n",
    "    except Exception as e:\n",
    "        # Handle the exception\n",
    "        print(f\"Error occurred while scraping book '{book}': {e}\")\n",
    "        return \"N/A\", \"N/A\", \"N/A\", [\"N/A\"]\n",
    "\n",
    "# Select the top n books from the book_list\n",
    "top_books = book_list\n",
    "\n",
    "# Initialize lists\n",
    "descriptions = []\n",
    "authors = []\n",
    "links = []\n",
    "genres = []\n",
    "\n",
    "# Iterate over the top_books\n",
    "for book in top_books:\n",
    "    description, author, link, genre = scrape_book_details(book)\n",
    "    iteration_count = 0\n",
    "\n",
    "    # Re-scrape if any value is \"N/A\" or [\"N/A\"]\n",
    "    while (description == \"N/A\" or author == \"N/A\" or link == \"N/A\" or genre == [\"N/A\"]) and iteration_count < 4:\n",
    "        print(f\"Re-scraping book '{book}' (Iteration {iteration_count + 1})...\")\n",
    "        description, author, link, genre = scrape_book_details(book)\n",
    "        iteration_count += 1\n",
    "\n",
    "\n",
    "    descriptions.append(description)\n",
    "    authors.append(author)\n",
    "    links.append(link)\n",
    "    genres.append(genre)\n",
    "\n",
    "\n",
    "# Create a dictionary with book details\n",
    "data = {\n",
    "    \"Book Title\": top_books,\n",
    "    \"Description\": descriptions,\n",
    "    \"Author\": authors,\n",
    "    \"Link\": links,\n",
    "    \"Genres\": genres\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a45f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df.head(102)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab383cfd",
   "metadata": {},
   "source": [
    "# Tokenize the description using spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ac715d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_md\n",
    "import ast\n",
    "nlp = en_core_web_md.load()\n",
    "remove_tag= ['ADV','PRON','CCONJ','PUNCT','PART','DET','ADP','SPACE', 'NUM', 'SYM'] # source: suggested by chatgpt\n",
    "nlp.Defaults.stop_words |= {\"the\",\"so\",\"good\",\"book\",\"author\",\"life\",\"novel\",\"reader\",\"edition\",\"writer\",\"write\",\"new\",\"world\",\"story\",\"year\"}\n",
    "\n",
    "#tokenize descriptions\n",
    "tokens = []\n",
    "\n",
    "#pretrained en_core_web_md model for token words\n",
    "for description in nlp.pipe(df[\"Description\"]):\n",
    "    tokenized_description = []\n",
    "    #keep only desired tokens\n",
    "    for token in description:\n",
    "        #select adequate tags, skip stopwords and skip non-alphabetic\n",
    "        if token.pos_ not in remove_tag and not token.is_stop and token.is_alpha:\n",
    "            #use the lower case lemma for token\n",
    "            tokenized_description.append(token.lemma_.lower())\n",
    "    tokens.append(tokenized_description)\n",
    "\n",
    "df['tokens'] = tokens\n",
    "display(df['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f99e608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary module from Gensim\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "# Create a dictionary object from the tokenized descriptions\n",
    "# Each token is assigned a unique ID and the frequency of occurrence is tracked\n",
    "dictionary = Dictionary(df['tokens'])\n",
    "\n",
    "# Filter the dictionary to remove infrequent and overly common tokens\n",
    "# The parameters specify the filtering criteria\n",
    "# - no_below: Remove tokens that appear in fewer than 5 books/documents\n",
    "# - no_above: Remove tokens that appear in more than 50% of the books/documents\n",
    "# - keep_n: Keep the top 1000 most frequent tokens in the dictionary\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.5, keep_n=1000)\n",
    "\n",
    "# Create a corpus representation of the tokenized descriptions using the filtered dictionary\n",
    "# The corpus is a list of bag-of-words vectors, with each vector representing a document\n",
    "corpus = [dictionary.doc2bow(doc) for doc in df['tokens']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281a3033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules for visualization, LDA modeling, and coherence scoring\n",
    "import matplotlib.pyplot as plt\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "pyLDAvis.enable_notebook()\n",
    "from gensim.models import LdaMulticore\n",
    "from gensim.models import CoherenceModel\n",
    "import matplotlib as plt\n",
    "# Create empty lists to store the number of topics and coherence scores\n",
    "topics = []\n",
    "score = []\n",
    "\n",
    "# Iterate over a range of values from 1 to 9 (exclusive) with a step size of 1\n",
    "for i in range(1, 10, 1):\n",
    "    # Train an LDA model using LdaMulticore\n",
    "    lda_model = LdaMulticore(corpus=corpus, id2word=dictionary, iterations=10, num_topics=i, workers=14, passes=10, random_state=100)\n",
    "    \n",
    "    # Calculate the coherence score using CoherenceModel\n",
    "    cm = CoherenceModel(model=lda_model, texts=df['tokens'], corpus=corpus, dictionary=dictionary, coherence='c_v')\n",
    "    \n",
    "    # Append the current number of topics and coherence score to the respective lists\n",
    "    topics.append(i)\n",
    "    score.append(cm.get_coherence())\n",
    "\n",
    "# Plot the number of topics on the x-axis and the coherence score on the y-axis\n",
    "plt.plot(topics, score)\n",
    "\n",
    "# Add labels to the x-axis and y-axis\n",
    "plt.xlabel('Number of Topics')\n",
    "plt.ylabel('Coherence Score')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc8c24c",
   "metadata": {},
   "source": [
    "The higher the coherence score the better, in this case I decide to go with 6 topics\n",
    "\n",
    "training an LDA model with the following parameters:\n",
    "- corpus: The corpus of bag-of-words vectors.\n",
    "- id2word: The dictionary mapping word IDs to words.\n",
    "- iterations: The number of iterations for model training (set to 100).\n",
    "- num_topics: The number of topics to be generated by the model (set to 6).\n",
    "- workers: The number of core for training (set to 14).\n",
    "- passes: The number of passes over the corpus during training (set to 100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e057f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LdaMulticore(corpus=corpus, id2word=dictionary, iterations=100, num_topics= 6 , workers = 14 , passes=100)\n",
    "#print all object\n",
    "lda_model.print_topics(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a2418b",
   "metadata": {},
   "source": [
    "Visulize the topics' distribution and the most relevant terms for each topic.\n",
    "PC1 and PC2 represent the first two principal components obtained from PCA(summary indices). The distance between points indicates the similarity or dissimilarity between topics. For example, the position of the topics on the plot is determined by their distribution of words and how they relate to each other in terms of their probabilities. Topics that are similar or have overlapping word distributions will be closer to each other on the plot, while dissimilar topics will be farther apart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82533bf2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lda_display = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary)\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c548dc32",
   "metadata": {},
   "source": [
    "Association with topics and genres?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efd2fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the topic-word matrix from the LDA model\n",
    "topic_word_matrix = lda_model.show_topics(formatted=False)\n",
    "\n",
    "# Iterate over each topic and its associated words\n",
    "for topic_id, topic_words in topic_word_matrix:\n",
    "    print(f\"Topic ID: {topic_id}\")\n",
    "    words = [word for word, _ in topic_words]\n",
    "    print(f\"Words: {', '.join(words)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f37f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the 'Genres' column\n",
    "all_genres = [genre for genres_list in df['Genres'] for genre in genres_list]\n",
    "\n",
    "# Get the unique genres\n",
    "unique_genres = set(all_genres)\n",
    "\n",
    "# Print the unique genres\n",
    "print(unique_genres)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
